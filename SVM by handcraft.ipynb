{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a9e68ce5/Machine-Learning/blob/main/SVM%20by%20handcraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC_P8bFMzILD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "seed = 3047\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
        "!gdown 1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
        "!gdown 1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2"
      ],
      "metadata": {
        "id": "FucrkOKI3m_c",
        "outputId": "89ee9fa4-8002-4085-d666-3ec4991c587c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
            "To: /content/train.csv\n",
            "100% 6.54M/6.54M [00:00<00:00, 45.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
            "To: /content/val.csv\n",
            "100% 665k/665k [00:00<00:00, 117MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2\n",
            "To: /content/X_test\n",
            "100% 3.57M/3.57M [00:00<00:00, 278MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features=[\"age\", 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']"
      ],
      "metadata": {
        "id": "TYhollGQ8i04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM(nn.Module):\n",
        "  def __init__(self):\n",
        "    # TODO design your model\n",
        "    super(SVM, self).__init__()\n",
        "    self.w = nn.Parameter(torch.randn((1, 1024)).to(torch.float32))#outi∼N(0,1)\n",
        "    self.f = nn.Sequential(\n",
        "                  nn.Linear(107, 128),\n",
        "                  nn.Dropout(0.5),\n",
        "                  nn.LeakyReLU(negative_slope=0.05),\n",
        "                  nn.Linear(128,256),\n",
        "                  nn.LeakyReLU(negative_slope=0.05),\n",
        "                  nn.Linear(256,512),\n",
        "                  nn.LeakyReLU(negative_slope=0.05),\n",
        "                  nn.Linear(512,1024),\n",
        "                )\n",
        "  def transform(self, x):\n",
        "    x = self.f(x)\n",
        "    return x\n",
        "  def kernel(self, x):\n",
        "    pass\n",
        "  def forward(self, x):\n",
        "    f = torch.matmul(self.transform(x), self.w.T)\n",
        "\n",
        "    return f"
      ],
      "metadata": {
        "id": "Iywj8wLF8ppU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HingeLoss(nn.Module):\n",
        "  def __init__(self, C):\n",
        "    super(HingeLoss, self).__init__()\n",
        "    self.C = C\n",
        "  def forward(self, y, f):\n",
        "    #y=y.detach().cpu().numpy()\n",
        "    #f=f.detach().cpu().numpy()\n",
        "    loss=0.0\n",
        "    one = torch.ones(len(y)).cuda()\n",
        "    two = (2 * one).cuda()\n",
        "    l = torch.sub(one , torch.mul(y , f)).cuda()\n",
        "    lt = torch.div(torch.add(torch.sign(l),one),two).cuda()\n",
        "    loss = torch.sum(torch.mul(l,lt)).cuda() # define Hinge loss\n",
        "    return self.C * loss\n"
      ],
      "metadata": {
        "id": "X2a0522z7IWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "  def __init__(self, split, mu=None, std=None):\n",
        "    X = pd.read_csv(f\"{split}.csv\")\n",
        "\n",
        "    Y = X['y'].values.reshape(-1) * 2 - 1\n",
        "    X = X.drop(labels=['y'],axis=1)#106\n",
        "    X_nodummy = self.normalize(X, mu, std)\n",
        "    X_dummy = X.drop(features,axis=1)\n",
        "    f = [X_nodummy,X_dummy]\n",
        "    X = pd.concat(f,axis=1)\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.Y = torch.from_numpy(Y).to(torch.float32)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self, X, mu=None, std=None):\n",
        "    mu_x = X[features].mean()\n",
        "    std_x = X[features].std()\n",
        "    X = (X[features]-mu_x)/std_x\n",
        "\n",
        "    return X\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, mu=None, std=None):\n",
        "    X = pd.read_csv(\"X_test\")\n",
        "    X_nodummy = self.normalize(X, mu, std)\n",
        "    X_dummy = X.drop(features,axis=1)\n",
        "    f = [X_nodummy,X_dummy]\n",
        "    X = pd.concat(f,axis=1)\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self, X, mu_x=None, std_x=None):\n",
        "    mu_x = X[features].mean()\n",
        "    std_x = X[features].std()\n",
        "    X = (X[features]-mu_x)/std_x\n",
        "\n",
        "    return X\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx]"
      ],
      "metadata": {
        "id": "iBTrbIzE_AI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_data, val_data, model, optim, C, device='cuda:0'):\n",
        "    epoch = 100\n",
        "    objective = HingeLoss(C)\n",
        "    steps = 0\n",
        "    best = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "      for tr in train_data:\n",
        "        steps += 1\n",
        "        x_train, y_train = tr\n",
        "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "        pred = model(x_train).squeeze(1)\n",
        "        loss = objective(pred, y_train) + 1 / 2 * torch.sum(model.w[:-1] ** 2)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "        if steps % 100 == 0:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            acc = []\n",
        "            for val in val_data:\n",
        "              x_val, y_val = val\n",
        "              x_val , y_val = x_val.to(device), y_val.to(device)\n",
        "              pred = model(x_val).squeeze(1)\n",
        "              pred = (pred > 0) * 2 - 1\n",
        "\n",
        "              result = (y_val == pred)\n",
        "              acc += [(float(result.sum()) / result.size(0))]\n",
        "            acc = sum(acc) / len(acc)\n",
        "            print(f'Steps {steps}| Train Loss = {loss.item()}| Val acc = {acc}')\n",
        "            if acc > best:\n",
        "              torch.save(model.state_dict(), 'best.ckpt')\n",
        "              print('model saved to best.ckpt' )\n",
        "              best = acc\n",
        "          model.train()\n",
        "    return model"
      ],
      "metadata": {
        "id": "m5PZP044Pxuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001 #原本得太大要改小一點\n",
        "batch = 32\n",
        "C = 1\n",
        "device = 'cuda:0'"
      ],
      "metadata": {
        "id": "ucnbZEiVPia3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TrainDataset('train')\n",
        "devset = TrainDataset('val')\n",
        "testset = TestDataset()\n",
        "\n",
        "train_dataloader = DataLoader(trainset, batch, True, drop_last=False)\n",
        "val_dataloader = DataLoader(devset, 1, False)\n",
        "test_dataloader = DataLoader(testset, 1, False)\n",
        "\n",
        "model = SVM().to(device)\n",
        "optim = SGD(model.parameters(), lr)\n",
        "model = train(train_dataloader, val_dataloader, model, optim, C, device)"
      ],
      "metadata": {
        "id": "YF1QyZXG4eI7",
        "outputId": "7d020cc6-2676-43d1-cd5d-d839943f9e93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps 100| Train Loss = 8.749897956848145| Val acc = 0.7696666666666667\n",
            "model saved to best.ckpt\n",
            "Steps 200| Train Loss = 10.213069915771484| Val acc = 0.8033333333333333\n",
            "model saved to best.ckpt\n",
            "Steps 300| Train Loss = 12.723794937133789| Val acc = 0.8156666666666667\n",
            "model saved to best.ckpt\n",
            "Steps 400| Train Loss = 9.709233283996582| Val acc = 0.8116666666666666\n",
            "Steps 500| Train Loss = 15.825675010681152| Val acc = 0.775\n",
            "Steps 600| Train Loss = 9.970705032348633| Val acc = 0.834\n",
            "model saved to best.ckpt\n",
            "Steps 700| Train Loss = 10.852099418640137| Val acc = 0.826\n",
            "Steps 800| Train Loss = 28.935596466064453| Val acc = 0.814\n",
            "Steps 900| Train Loss = 13.653066635131836| Val acc = 0.7903333333333333\n",
            "Steps 1000| Train Loss = 14.782269477844238| Val acc = 0.7996666666666666\n",
            "Steps 1100| Train Loss = 16.88784408569336| Val acc = 0.8373333333333334\n",
            "model saved to best.ckpt\n",
            "Steps 1200| Train Loss = 14.495923042297363| Val acc = 0.8363333333333334\n",
            "Steps 1300| Train Loss = 12.889062881469727| Val acc = 0.8366666666666667\n",
            "Steps 1400| Train Loss = 11.244338989257812| Val acc = 0.8373333333333334\n",
            "Steps 1500| Train Loss = 13.01284408569336| Val acc = 0.844\n",
            "model saved to best.ckpt\n",
            "Steps 1600| Train Loss = 14.183876991271973| Val acc = 0.841\n",
            "Steps 1700| Train Loss = 18.348054885864258| Val acc = 0.8473333333333334\n",
            "model saved to best.ckpt\n",
            "Steps 1800| Train Loss = 14.668937683105469| Val acc = 0.8193333333333334\n",
            "Steps 1900| Train Loss = 12.01260757446289| Val acc = 0.8433333333333334\n",
            "Steps 2000| Train Loss = 4.96980094909668| Val acc = 0.7893333333333333\n",
            "Steps 2100| Train Loss = 13.961639404296875| Val acc = 0.8283333333333334\n",
            "Steps 2200| Train Loss = 13.310746192932129| Val acc = 0.844\n",
            "Steps 2300| Train Loss = 10.878171920776367| Val acc = 0.847\n",
            "Steps 2400| Train Loss = 7.038894176483154| Val acc = 0.8213333333333334\n",
            "Steps 2500| Train Loss = 4.77908992767334| Val acc = 0.8323333333333334\n",
            "Steps 2600| Train Loss = 9.746849060058594| Val acc = 0.845\n",
            "Steps 2700| Train Loss = 9.168598175048828| Val acc = 0.8446666666666667\n",
            "Steps 2800| Train Loss = 10.267513275146484| Val acc = 0.833\n",
            "Steps 2900| Train Loss = 9.575803756713867| Val acc = 0.8423333333333334\n",
            "Steps 3000| Train Loss = 4.831307411193848| Val acc = 0.8376666666666667\n",
            "Steps 3100| Train Loss = 4.728876113891602| Val acc = 0.8246666666666667\n",
            "Steps 3200| Train Loss = 4.597439765930176| Val acc = 0.8406666666666667\n",
            "Steps 3300| Train Loss = 13.909409523010254| Val acc = 0.8216666666666667\n",
            "Steps 3400| Train Loss = 11.606741905212402| Val acc = 0.8246666666666667\n",
            "Steps 3500| Train Loss = 10.838811874389648| Val acc = 0.841\n",
            "Steps 3600| Train Loss = 14.717111587524414| Val acc = 0.8433333333333334\n",
            "Steps 3700| Train Loss = 3.9033989906311035| Val acc = 0.8293333333333334\n",
            "Steps 3800| Train Loss = 13.663387298583984| Val acc = 0.8436666666666667\n",
            "Steps 3900| Train Loss = 10.311767578125| Val acc = 0.83\n",
            "Steps 4000| Train Loss = 11.526067733764648| Val acc = 0.8446666666666667\n",
            "Steps 4100| Train Loss = 10.99702262878418| Val acc = 0.843\n",
            "Steps 4200| Train Loss = 10.59416389465332| Val acc = 0.8456666666666667\n",
            "Steps 4300| Train Loss = 9.75689697265625| Val acc = 0.844\n",
            "Steps 4400| Train Loss = 8.884227752685547| Val acc = 0.8256666666666667\n",
            "Steps 4500| Train Loss = 15.759838104248047| Val acc = 0.8286666666666667\n",
            "Steps 4600| Train Loss = 4.457398414611816| Val acc = 0.8453333333333334\n",
            "Steps 4700| Train Loss = 8.407381057739258| Val acc = 0.844\n",
            "Steps 4800| Train Loss = 13.855769157409668| Val acc = 0.8453333333333334\n",
            "Steps 4900| Train Loss = 10.80976676940918| Val acc = 0.8196666666666667\n",
            "Steps 5000| Train Loss = 12.460994720458984| Val acc = 0.8456666666666667\n",
            "Steps 5100| Train Loss = 13.767133712768555| Val acc = 0.844\n",
            "Steps 5200| Train Loss = 11.456693649291992| Val acc = 0.845\n",
            "Steps 5300| Train Loss = 12.728392601013184| Val acc = 0.8436666666666667\n",
            "Steps 5400| Train Loss = 12.731935501098633| Val acc = 0.8463333333333334\n",
            "Steps 5500| Train Loss = 12.942779541015625| Val acc = 0.8456666666666667\n",
            "Steps 5600| Train Loss = 19.497150421142578| Val acc = 0.8443333333333334\n",
            "Steps 5700| Train Loss = 13.859167098999023| Val acc = 0.8446666666666667\n",
            "Steps 5800| Train Loss = 14.641204833984375| Val acc = 0.8266666666666667\n",
            "Steps 5900| Train Loss = 2.015380859375| Val acc = 0.843\n",
            "Steps 6000| Train Loss = 18.050636291503906| Val acc = 0.842\n",
            "Steps 6100| Train Loss = 8.961071968078613| Val acc = 0.8433333333333334\n",
            "Steps 6200| Train Loss = 4.987778663635254| Val acc = 0.845\n",
            "Steps 6300| Train Loss = 8.484341621398926| Val acc = 0.8463333333333334\n",
            "Steps 6400| Train Loss = 16.311737060546875| Val acc = 0.8433333333333334\n",
            "Steps 6500| Train Loss = 9.640510559082031| Val acc = 0.844\n",
            "Steps 6600| Train Loss = 18.37670135498047| Val acc = 0.8453333333333334\n",
            "Steps 6700| Train Loss = 6.549923896789551| Val acc = 0.8363333333333334\n",
            "Steps 6800| Train Loss = 17.425067901611328| Val acc = 0.8246666666666667\n",
            "Steps 6900| Train Loss = 12.03642463684082| Val acc = 0.8426666666666667\n",
            "Steps 7000| Train Loss = 13.101659774780273| Val acc = 0.844\n",
            "Steps 7100| Train Loss = 13.998891830444336| Val acc = 0.8446666666666667\n",
            "Steps 7200| Train Loss = 12.154867172241211| Val acc = 0.845\n",
            "Steps 7300| Train Loss = 10.443963050842285| Val acc = 0.846\n",
            "Steps 7400| Train Loss = 15.66554069519043| Val acc = 0.8423333333333334\n",
            "Steps 7500| Train Loss = 11.224000930786133| Val acc = 0.839\n",
            "Steps 7600| Train Loss = 21.737201690673828| Val acc = 0.847\n",
            "Steps 7700| Train Loss = 15.502432823181152| Val acc = 0.8466666666666667\n",
            "Steps 7800| Train Loss = 7.798264503479004| Val acc = 0.846\n",
            "Steps 7900| Train Loss = 12.449631690979004| Val acc = 0.845\n",
            "Steps 8000| Train Loss = 16.199129104614258| Val acc = 0.8456666666666667\n",
            "Steps 8100| Train Loss = 6.521533489227295| Val acc = 0.842\n",
            "Steps 8200| Train Loss = 13.293231964111328| Val acc = 0.841\n",
            "Steps 8300| Train Loss = 7.841104507446289| Val acc = 0.844\n",
            "Steps 8400| Train Loss = 14.479454040527344| Val acc = 0.8426666666666667\n",
            "Steps 8500| Train Loss = 10.707581520080566| Val acc = 0.83\n",
            "Steps 8600| Train Loss = 9.820417404174805| Val acc = 0.843\n",
            "Steps 8700| Train Loss = 10.305343627929688| Val acc = 0.8463333333333334\n",
            "Steps 8800| Train Loss = 15.705568313598633| Val acc = 0.844\n",
            "Steps 8900| Train Loss = 10.45307445526123| Val acc = 0.844\n",
            "Steps 9000| Train Loss = 12.933821678161621| Val acc = 0.8426666666666667\n",
            "Steps 9100| Train Loss = 8.238892555236816| Val acc = 0.8443333333333334\n",
            "Steps 9200| Train Loss = 14.328914642333984| Val acc = 0.8436666666666667\n",
            "Steps 9300| Train Loss = 10.862637519836426| Val acc = 0.8456666666666667\n",
            "Steps 9400| Train Loss = 9.907236099243164| Val acc = 0.8453333333333334\n",
            "Steps 9500| Train Loss = 13.02587890625| Val acc = 0.8433333333333334\n",
            "Steps 9600| Train Loss = 17.289779663085938| Val acc = 0.8466666666666667\n",
            "Steps 9700| Train Loss = 21.061023712158203| Val acc = 0.8456666666666667\n",
            "Steps 9800| Train Loss = 5.992168426513672| Val acc = 0.844\n",
            "Steps 9900| Train Loss = 9.501288414001465| Val acc = 0.8473333333333334\n",
            "Steps 10000| Train Loss = 15.124433517456055| Val acc = 0.843\n",
            "Steps 10100| Train Loss = 10.30241584777832| Val acc = 0.8436666666666667\n",
            "Steps 10200| Train Loss = 8.060432434082031| Val acc = 0.8456666666666667\n",
            "Steps 10300| Train Loss = 10.26777458190918| Val acc = 0.8466666666666667\n",
            "Steps 10400| Train Loss = 4.841946601867676| Val acc = 0.8443333333333334\n",
            "Steps 10500| Train Loss = 5.852515697479248| Val acc = 0.846\n",
            "Steps 10600| Train Loss = 11.166717529296875| Val acc = 0.8476666666666667\n",
            "model saved to best.ckpt\n",
            "Steps 10700| Train Loss = 13.47061538696289| Val acc = 0.8423333333333334\n",
            "Steps 10800| Train Loss = 4.914808750152588| Val acc = 0.8433333333333334\n",
            "Steps 10900| Train Loss = 12.555742263793945| Val acc = 0.8423333333333334\n",
            "Steps 11000| Train Loss = 14.004347801208496| Val acc = 0.8483333333333334\n",
            "model saved to best.ckpt\n",
            "Steps 11100| Train Loss = 12.52877426147461| Val acc = 0.8453333333333334\n",
            "Steps 11200| Train Loss = 8.543722152709961| Val acc = 0.8453333333333334\n",
            "Steps 11300| Train Loss = 15.142111778259277| Val acc = 0.8456666666666667\n",
            "Steps 11400| Train Loss = 6.243220329284668| Val acc = 0.8443333333333334\n",
            "Steps 11500| Train Loss = 11.20373249053955| Val acc = 0.8433333333333334\n",
            "Steps 11600| Train Loss = 8.018397331237793| Val acc = 0.8466666666666667\n",
            "Steps 11700| Train Loss = 12.61291790008545| Val acc = 0.8476666666666667\n",
            "Steps 11800| Train Loss = 15.944473266601562| Val acc = 0.846\n",
            "Steps 11900| Train Loss = 10.408504486083984| Val acc = 0.8436666666666667\n",
            "Steps 12000| Train Loss = 14.273782730102539| Val acc = 0.8406666666666667\n",
            "Steps 12100| Train Loss = 13.45073413848877| Val acc = 0.8443333333333334\n",
            "Steps 12200| Train Loss = 2.8861846923828125| Val acc = 0.8423333333333334\n",
            "Steps 12300| Train Loss = 18.67966651916504| Val acc = 0.8456666666666667\n",
            "Steps 12400| Train Loss = 7.3947224617004395| Val acc = 0.844\n",
            "Steps 12500| Train Loss = 8.804020881652832| Val acc = 0.844\n",
            "Steps 12600| Train Loss = 22.517078399658203| Val acc = 0.8456666666666667\n",
            "Steps 12700| Train Loss = 12.038223266601562| Val acc = 0.843\n",
            "Steps 12800| Train Loss = 10.727689743041992| Val acc = 0.8446666666666667\n",
            "Steps 12900| Train Loss = 7.553478240966797| Val acc = 0.844\n",
            "Steps 13000| Train Loss = 12.542098999023438| Val acc = 0.8443333333333334\n",
            "Steps 13100| Train Loss = 12.819355010986328| Val acc = 0.8416666666666667\n",
            "Steps 13200| Train Loss = 5.362109184265137| Val acc = 0.8453333333333334\n",
            "Steps 13300| Train Loss = 9.116050720214844| Val acc = 0.844\n",
            "Steps 13400| Train Loss = 12.08658504486084| Val acc = 0.845\n",
            "Steps 13500| Train Loss = 15.620879173278809| Val acc = 0.8456666666666667\n",
            "Steps 13600| Train Loss = 15.31241226196289| Val acc = 0.8453333333333334\n",
            "Steps 13700| Train Loss = 9.208712577819824| Val acc = 0.847\n",
            "Steps 13800| Train Loss = 8.654081344604492| Val acc = 0.8393333333333334\n",
            "Steps 13900| Train Loss = 2.062699317932129| Val acc = 0.845\n",
            "Steps 14000| Train Loss = 8.6965913772583| Val acc = 0.8456666666666667\n",
            "Steps 14100| Train Loss = 8.39572525024414| Val acc = 0.848\n",
            "Steps 14200| Train Loss = 13.619064331054688| Val acc = 0.847\n",
            "Steps 14300| Train Loss = 9.525714874267578| Val acc = 0.847\n",
            "Steps 14400| Train Loss = 8.60797119140625| Val acc = 0.8473333333333334\n",
            "Steps 14500| Train Loss = 7.228321075439453| Val acc = 0.8466666666666667\n",
            "Steps 14600| Train Loss = 15.375015258789062| Val acc = 0.8456666666666667\n",
            "Steps 14700| Train Loss = 15.714921951293945| Val acc = 0.8286666666666667\n",
            "Steps 14800| Train Loss = 11.904390335083008| Val acc = 0.847\n",
            "Steps 14900| Train Loss = 12.044230461120605| Val acc = 0.845\n",
            "Steps 15000| Train Loss = 11.035002708435059| Val acc = 0.8453333333333334\n",
            "Steps 15100| Train Loss = 10.726075172424316| Val acc = 0.847\n",
            "Steps 15200| Train Loss = 7.397363662719727| Val acc = 0.8476666666666667\n",
            "Steps 15300| Train Loss = 13.055193901062012| Val acc = 0.8453333333333334\n",
            "Steps 15400| Train Loss = 8.430511474609375| Val acc = 0.8483333333333334\n",
            "Steps 15500| Train Loss = 8.766668319702148| Val acc = 0.8466666666666667\n",
            "Steps 15600| Train Loss = 13.865476608276367| Val acc = 0.8456666666666667\n",
            "Steps 15700| Train Loss = 13.513323783874512| Val acc = 0.8463333333333334\n",
            "Steps 15800| Train Loss = 8.325542449951172| Val acc = 0.8483333333333334\n",
            "Steps 15900| Train Loss = 9.314544677734375| Val acc = 0.844\n",
            "Steps 16000| Train Loss = 19.679489135742188| Val acc = 0.8476666666666667\n",
            "Steps 16100| Train Loss = 12.741439819335938| Val acc = 0.8393333333333334\n",
            "Steps 16200| Train Loss = 5.963737487792969| Val acc = 0.8436666666666667\n",
            "Steps 16300| Train Loss = 17.499649047851562| Val acc = 0.848\n",
            "Steps 16400| Train Loss = 4.51801061630249| Val acc = 0.8426666666666667\n",
            "Steps 16500| Train Loss = 6.456151008605957| Val acc = 0.844\n",
            "Steps 16600| Train Loss = 12.98202896118164| Val acc = 0.848\n",
            "Steps 16700| Train Loss = 6.357388973236084| Val acc = 0.845\n",
            "Steps 16800| Train Loss = 7.094182014465332| Val acc = 0.8433333333333334\n",
            "Steps 16900| Train Loss = 14.93521785736084| Val acc = 0.8493333333333334\n",
            "model saved to best.ckpt\n",
            "Steps 17000| Train Loss = 16.28946876525879| Val acc = 0.8473333333333334\n",
            "Steps 17100| Train Loss = 14.66452693939209| Val acc = 0.848\n",
            "Steps 17200| Train Loss = 16.27637481689453| Val acc = 0.8506666666666667\n",
            "model saved to best.ckpt\n",
            "Steps 17300| Train Loss = 7.843940734863281| Val acc = 0.845\n",
            "Steps 17400| Train Loss = 5.922491073608398| Val acc = 0.8463333333333334\n",
            "Steps 17500| Train Loss = 13.717046737670898| Val acc = 0.8416666666666667\n",
            "Steps 17600| Train Loss = 7.385112762451172| Val acc = 0.8473333333333334\n",
            "Steps 17700| Train Loss = 5.027246952056885| Val acc = 0.845\n",
            "Steps 17800| Train Loss = 14.520649909973145| Val acc = 0.847\n",
            "Steps 17900| Train Loss = 13.300737380981445| Val acc = 0.8466666666666667\n",
            "Steps 18000| Train Loss = 9.025871276855469| Val acc = 0.843\n",
            "Steps 18100| Train Loss = 7.628041744232178| Val acc = 0.8446666666666667\n",
            "Steps 18200| Train Loss = 5.830648899078369| Val acc = 0.8493333333333334\n",
            "Steps 18300| Train Loss = 18.251110076904297| Val acc = 0.8476666666666667\n",
            "Steps 18400| Train Loss = 6.995025634765625| Val acc = 0.8483333333333334\n",
            "Steps 18500| Train Loss = 6.954678058624268| Val acc = 0.8456666666666667\n",
            "Steps 18600| Train Loss = 13.278039932250977| Val acc = 0.8466666666666667\n",
            "Steps 18700| Train Loss = 14.252799034118652| Val acc = 0.847\n",
            "Steps 18800| Train Loss = 11.298025131225586| Val acc = 0.8413333333333334\n",
            "Steps 18900| Train Loss = 15.085330963134766| Val acc = 0.844\n",
            "Steps 19000| Train Loss = 10.595418930053711| Val acc = 0.846\n",
            "Steps 19100| Train Loss = 9.65275764465332| Val acc = 0.849\n",
            "Steps 19200| Train Loss = 4.897723197937012| Val acc = 0.8466666666666667\n",
            "Steps 19300| Train Loss = 9.40949821472168| Val acc = 0.8463333333333334\n",
            "Steps 19400| Train Loss = 8.079872131347656| Val acc = 0.8446666666666667\n",
            "Steps 19500| Train Loss = 5.817296028137207| Val acc = 0.8456666666666667\n",
            "Steps 19600| Train Loss = 10.076683044433594| Val acc = 0.846\n",
            "Steps 19700| Train Loss = 12.58662223815918| Val acc = 0.8476666666666667\n",
            "Steps 19800| Train Loss = 11.6664400100708| Val acc = 0.8463333333333334\n",
            "Steps 19900| Train Loss = 15.945965766906738| Val acc = 0.8476666666666667\n",
            "Steps 20000| Train Loss = 9.699719429016113| Val acc = 0.8473333333333334\n",
            "Steps 20100| Train Loss = 3.3126978874206543| Val acc = 0.8483333333333334\n",
            "Steps 20200| Train Loss = 6.403984546661377| Val acc = 0.8486666666666667\n",
            "Steps 20300| Train Loss = 13.647653579711914| Val acc = 0.8456666666666667\n",
            "Steps 20400| Train Loss = 7.453997611999512| Val acc = 0.847\n",
            "Steps 20500| Train Loss = 6.58782434463501| Val acc = 0.847\n",
            "Steps 20600| Train Loss = 10.708982467651367| Val acc = 0.8476666666666667\n",
            "Steps 20700| Train Loss = 9.150083541870117| Val acc = 0.8473333333333334\n",
            "Steps 20800| Train Loss = 19.231388092041016| Val acc = 0.841\n",
            "Steps 20900| Train Loss = 7.287507057189941| Val acc = 0.8436666666666667\n",
            "Steps 21000| Train Loss = 16.577518463134766| Val acc = 0.8453333333333334\n",
            "Steps 21100| Train Loss = 10.018985748291016| Val acc = 0.8473333333333334\n",
            "Steps 21200| Train Loss = 2.8141143321990967| Val acc = 0.849\n",
            "Steps 21300| Train Loss = 16.175167083740234| Val acc = 0.8506666666666667\n",
            "Steps 21400| Train Loss = 10.137975692749023| Val acc = 0.8486666666666667\n",
            "Steps 21500| Train Loss = 7.558132648468018| Val acc = 0.8456666666666667\n",
            "Steps 21600| Train Loss = 12.878007888793945| Val acc = 0.846\n",
            "Steps 21700| Train Loss = 14.845697402954102| Val acc = 0.8483333333333334\n",
            "Steps 21800| Train Loss = 6.860942840576172| Val acc = 0.8486666666666667\n",
            "Steps 21900| Train Loss = 6.53667688369751| Val acc = 0.8473333333333334\n",
            "Steps 22000| Train Loss = 7.07940673828125| Val acc = 0.8483333333333334\n",
            "Steps 22100| Train Loss = 9.333003997802734| Val acc = 0.8456666666666667\n",
            "Steps 22200| Train Loss = 7.131113052368164| Val acc = 0.8486666666666667\n",
            "Steps 22300| Train Loss = 19.014102935791016| Val acc = 0.8476666666666667\n",
            "Steps 22400| Train Loss = 7.005637168884277| Val acc = 0.8476666666666667\n",
            "Steps 22500| Train Loss = 8.705131530761719| Val acc = 0.8466666666666667\n",
            "Steps 22600| Train Loss = 16.034332275390625| Val acc = 0.8483333333333334\n",
            "Steps 22700| Train Loss = 7.095937728881836| Val acc = 0.8453333333333334\n",
            "Steps 22800| Train Loss = 8.2781400680542| Val acc = 0.8486666666666667\n",
            "Steps 22900| Train Loss = 7.069079399108887| Val acc = 0.8483333333333334\n",
            "Steps 23000| Train Loss = 9.57171630859375| Val acc = 0.848\n",
            "Steps 23100| Train Loss = 2.720595359802246| Val acc = 0.8483333333333334\n",
            "Steps 23200| Train Loss = 6.462751388549805| Val acc = 0.849\n",
            "Steps 23300| Train Loss = 11.664107322692871| Val acc = 0.8476666666666667\n",
            "Steps 23400| Train Loss = 10.631783485412598| Val acc = 0.8493333333333334\n",
            "Steps 23500| Train Loss = 4.584005355834961| Val acc = 0.8463333333333334\n",
            "Steps 23600| Train Loss = 8.352273941040039| Val acc = 0.845\n",
            "Steps 23700| Train Loss = 8.554445266723633| Val acc = 0.8366666666666667\n",
            "Steps 23800| Train Loss = 11.767040252685547| Val acc = 0.852\n",
            "model saved to best.ckpt\n",
            "Steps 23900| Train Loss = 13.428506851196289| Val acc = 0.8463333333333334\n",
            "Steps 24000| Train Loss = 11.345544815063477| Val acc = 0.8466666666666667\n",
            "Steps 24100| Train Loss = 10.757732391357422| Val acc = 0.8476666666666667\n",
            "Steps 24200| Train Loss = 5.088099479675293| Val acc = 0.8473333333333334\n",
            "Steps 24300| Train Loss = 8.48775577545166| Val acc = 0.8456666666666667\n",
            "Steps 24400| Train Loss = 10.055320739746094| Val acc = 0.8466666666666667\n",
            "Steps 24500| Train Loss = 14.874629020690918| Val acc = 0.8453333333333334\n",
            "Steps 24600| Train Loss = 11.690315246582031| Val acc = 0.846\n",
            "Steps 24700| Train Loss = 12.841402053833008| Val acc = 0.8446666666666667\n",
            "Steps 24800| Train Loss = 10.469728469848633| Val acc = 0.846\n",
            "Steps 24900| Train Loss = 11.583209991455078| Val acc = 0.8456666666666667\n",
            "Steps 25000| Train Loss = 4.434039115905762| Val acc = 0.8446666666666667\n",
            "Steps 25100| Train Loss = 12.00402545928955| Val acc = 0.8463333333333334\n",
            "Steps 25200| Train Loss = 16.915260314941406| Val acc = 0.8443333333333334\n",
            "Steps 25300| Train Loss = 11.117424011230469| Val acc = 0.8476666666666667\n",
            "Steps 25400| Train Loss = 17.25112533569336| Val acc = 0.8476666666666667\n",
            "Steps 25500| Train Loss = 6.479861259460449| Val acc = 0.8483333333333334\n",
            "Steps 25600| Train Loss = 5.791423797607422| Val acc = 0.8466666666666667\n",
            "Steps 25700| Train Loss = 9.181694030761719| Val acc = 0.848\n",
            "Steps 25800| Train Loss = 14.411439895629883| Val acc = 0.848\n",
            "Steps 25900| Train Loss = 8.91901683807373| Val acc = 0.8456666666666667\n",
            "Steps 26000| Train Loss = 11.510164260864258| Val acc = 0.848\n",
            "Steps 26100| Train Loss = 15.76091194152832| Val acc = 0.8476666666666667\n",
            "Steps 26200| Train Loss = 7.370275497436523| Val acc = 0.8436666666666667\n",
            "Steps 26300| Train Loss = 16.295333862304688| Val acc = 0.8476666666666667\n",
            "Steps 26400| Train Loss = 11.654350280761719| Val acc = 0.8433333333333334\n",
            "Steps 26500| Train Loss = 13.356145858764648| Val acc = 0.8456666666666667\n",
            "Steps 26600| Train Loss = 4.948151111602783| Val acc = 0.8473333333333334\n",
            "Steps 26700| Train Loss = 7.456295490264893| Val acc = 0.8463333333333334\n",
            "Steps 26800| Train Loss = 13.045175552368164| Val acc = 0.8473333333333334\n",
            "Steps 26900| Train Loss = 14.695632934570312| Val acc = 0.846\n",
            "Steps 27000| Train Loss = 9.30720043182373| Val acc = 0.8456666666666667\n",
            "Steps 27100| Train Loss = 11.984841346740723| Val acc = 0.8476666666666667\n",
            "Steps 27200| Train Loss = 13.520211219787598| Val acc = 0.8476666666666667\n",
            "Steps 27300| Train Loss = 16.914113998413086| Val acc = 0.8466666666666667\n",
            "Steps 27400| Train Loss = 8.539083480834961| Val acc = 0.849\n",
            "Steps 27500| Train Loss = 15.757652282714844| Val acc = 0.8493333333333334\n",
            "Steps 27600| Train Loss = 2.2241134643554688| Val acc = 0.848\n",
            "Steps 27700| Train Loss = 10.267496109008789| Val acc = 0.8473333333333334\n",
            "Steps 27800| Train Loss = 15.69618034362793| Val acc = 0.85\n",
            "Steps 27900| Train Loss = 11.051414489746094| Val acc = 0.8483333333333334\n",
            "Steps 28000| Train Loss = 9.329221725463867| Val acc = 0.8486666666666667\n",
            "Steps 28100| Train Loss = 13.468867301940918| Val acc = 0.842\n",
            "Steps 28200| Train Loss = 12.74165153503418| Val acc = 0.8476666666666667\n",
            "Steps 28300| Train Loss = 15.316761016845703| Val acc = 0.8483333333333334\n",
            "Steps 28400| Train Loss = 5.46621561050415| Val acc = 0.848\n",
            "Steps 28500| Train Loss = 11.07894515991211| Val acc = 0.849\n",
            "Steps 28600| Train Loss = 9.19693660736084| Val acc = 0.8473333333333334\n",
            "Steps 28700| Train Loss = 6.281476974487305| Val acc = 0.8506666666666667\n",
            "Steps 28800| Train Loss = 4.334780693054199| Val acc = 0.849\n",
            "Steps 28900| Train Loss = 19.45932388305664| Val acc = 0.8486666666666667\n",
            "Steps 29000| Train Loss = 9.726635932922363| Val acc = 0.8466666666666667\n",
            "Steps 29100| Train Loss = 2.8817005157470703| Val acc = 0.8486666666666667\n",
            "Steps 29200| Train Loss = 13.74219799041748| Val acc = 0.8463333333333334\n",
            "Steps 29300| Train Loss = 9.408737182617188| Val acc = 0.8486666666666667\n",
            "Steps 29400| Train Loss = 21.153846740722656| Val acc = 0.8476666666666667\n",
            "Steps 29500| Train Loss = 10.744548797607422| Val acc = 0.8496666666666667\n",
            "Steps 29600| Train Loss = 17.40614128112793| Val acc = 0.8516666666666667\n",
            "Steps 29700| Train Loss = 10.576359748840332| Val acc = 0.8493333333333334\n",
            "Steps 29800| Train Loss = 15.667374610900879| Val acc = 0.8496666666666667\n",
            "Steps 29900| Train Loss = 6.133042335510254| Val acc = 0.8466666666666667\n",
            "Steps 30000| Train Loss = 7.212276458740234| Val acc = 0.8473333333333334\n",
            "Steps 30100| Train Loss = 5.832773685455322| Val acc = 0.8493333333333334\n",
            "Steps 30200| Train Loss = 7.1572265625| Val acc = 0.8476666666666667\n",
            "Steps 30300| Train Loss = 10.418684005737305| Val acc = 0.8476666666666667\n",
            "Steps 30400| Train Loss = 12.428751945495605| Val acc = 0.846\n",
            "Steps 30500| Train Loss = 8.673698425292969| Val acc = 0.846\n",
            "Steps 30600| Train Loss = 5.7399163246154785| Val acc = 0.8466666666666667\n",
            "Steps 30700| Train Loss = 9.797466278076172| Val acc = 0.8473333333333334\n",
            "Steps 30800| Train Loss = 9.818013191223145| Val acc = 0.8456666666666667\n",
            "Steps 30900| Train Loss = 10.709784507751465| Val acc = 0.849\n",
            "Steps 31000| Train Loss = 13.961970329284668| Val acc = 0.8466666666666667\n",
            "Steps 31100| Train Loss = 6.057864189147949| Val acc = 0.847\n",
            "Steps 31200| Train Loss = 17.047569274902344| Val acc = 0.8376666666666667\n",
            "Steps 31300| Train Loss = 12.365474700927734| Val acc = 0.849\n",
            "Steps 31400| Train Loss = 2.8746299743652344| Val acc = 0.8473333333333334\n",
            "Steps 31500| Train Loss = 5.99470329284668| Val acc = 0.8466666666666667\n",
            "Steps 31600| Train Loss = 3.998431444168091| Val acc = 0.849\n",
            "Steps 31700| Train Loss = 10.259180068969727| Val acc = 0.8476666666666667\n",
            "Steps 31800| Train Loss = 19.25132179260254| Val acc = 0.8486666666666667\n",
            "Steps 31900| Train Loss = 8.256000518798828| Val acc = 0.846\n",
            "Steps 32000| Train Loss = 6.579226970672607| Val acc = 0.85\n",
            "Steps 32100| Train Loss = 8.313867568969727| Val acc = 0.85\n",
            "Steps 32200| Train Loss = 5.107367515563965| Val acc = 0.847\n",
            "Steps 32300| Train Loss = 4.361701011657715| Val acc = 0.8476666666666667\n",
            "Steps 32400| Train Loss = 13.000003814697266| Val acc = 0.847\n",
            "Steps 32500| Train Loss = 7.713410377502441| Val acc = 0.8463333333333334\n",
            "Steps 32600| Train Loss = 5.8576555252075195| Val acc = 0.848\n",
            "Steps 32700| Train Loss = 6.7685322761535645| Val acc = 0.849\n",
            "Steps 32800| Train Loss = 9.848186492919922| Val acc = 0.8496666666666667\n",
            "Steps 32900| Train Loss = 16.072650909423828| Val acc = 0.848\n",
            "Steps 33000| Train Loss = 13.95270824432373| Val acc = 0.8486666666666667\n",
            "Steps 33100| Train Loss = 6.145890235900879| Val acc = 0.848\n",
            "Steps 33200| Train Loss = 15.686121940612793| Val acc = 0.849\n",
            "Steps 33300| Train Loss = 8.494303703308105| Val acc = 0.8473333333333334\n",
            "Steps 33400| Train Loss = 7.368496894836426| Val acc = 0.848\n",
            "Steps 33500| Train Loss = 4.661958694458008| Val acc = 0.8473333333333334\n",
            "Steps 33600| Train Loss = 5.53360652923584| Val acc = 0.8436666666666667\n",
            "Steps 33700| Train Loss = 5.745092391967773| Val acc = 0.847\n",
            "Steps 33800| Train Loss = 6.72798490524292| Val acc = 0.8463333333333334\n",
            "Steps 33900| Train Loss = 4.853777885437012| Val acc = 0.85\n",
            "Steps 34000| Train Loss = 7.025145053863525| Val acc = 0.8483333333333334\n",
            "Steps 34100| Train Loss = 7.832474708557129| Val acc = 0.847\n",
            "Steps 34200| Train Loss = 11.44578742980957| Val acc = 0.8463333333333334\n",
            "Steps 34300| Train Loss = 4.368886470794678| Val acc = 0.8486666666666667\n",
            "Steps 34400| Train Loss = 13.505655288696289| Val acc = 0.8493333333333334\n",
            "Steps 34500| Train Loss = 6.631101608276367| Val acc = 0.8493333333333334\n",
            "Steps 34600| Train Loss = 19.533180236816406| Val acc = 0.8493333333333334\n",
            "Steps 34700| Train Loss = 1.7263810634613037| Val acc = 0.846\n",
            "Steps 34800| Train Loss = 6.75723934173584| Val acc = 0.8463333333333334\n",
            "Steps 34900| Train Loss = 12.822336196899414| Val acc = 0.8496666666666667\n",
            "Steps 35000| Train Loss = 6.095859527587891| Val acc = 0.847\n",
            "Steps 35100| Train Loss = 11.050724983215332| Val acc = 0.848\n",
            "Steps 35200| Train Loss = 9.912368774414062| Val acc = 0.8493333333333334\n",
            "Steps 35300| Train Loss = 10.335561752319336| Val acc = 0.8493333333333334\n",
            "Steps 35400| Train Loss = 5.246476173400879| Val acc = 0.8496666666666667\n",
            "Steps 35500| Train Loss = 6.444511890411377| Val acc = 0.8476666666666667\n",
            "Steps 35600| Train Loss = 9.64639663696289| Val acc = 0.849\n",
            "Steps 35700| Train Loss = 7.7698869705200195| Val acc = 0.847\n",
            "Steps 35800| Train Loss = 8.492277145385742| Val acc = 0.8483333333333334\n",
            "Steps 35900| Train Loss = 11.919078826904297| Val acc = 0.8476666666666667\n",
            "Steps 36000| Train Loss = 20.500648498535156| Val acc = 0.8483333333333334\n",
            "Steps 36100| Train Loss = 13.898857116699219| Val acc = 0.842\n",
            "Steps 36200| Train Loss = 20.90013885498047| Val acc = 0.85\n",
            "Steps 36300| Train Loss = 3.6446704864501953| Val acc = 0.8483333333333334\n",
            "Steps 36400| Train Loss = 6.54845666885376| Val acc = 0.8473333333333334\n",
            "Steps 36500| Train Loss = 10.381511688232422| Val acc = 0.849\n",
            "Steps 36600| Train Loss = 9.490421295166016| Val acc = 0.8486666666666667\n",
            "Steps 36700| Train Loss = 6.038492202758789| Val acc = 0.851\n",
            "Steps 36800| Train Loss = 11.978090286254883| Val acc = 0.8503333333333334\n",
            "Steps 36900| Train Loss = 5.088253974914551| Val acc = 0.8473333333333334\n",
            "Steps 37000| Train Loss = 11.165933609008789| Val acc = 0.8466666666666667\n",
            "Steps 37100| Train Loss = 12.969039916992188| Val acc = 0.848\n",
            "Steps 37200| Train Loss = 12.45418643951416| Val acc = 0.85\n",
            "Steps 37300| Train Loss = 11.686330795288086| Val acc = 0.8496666666666667\n",
            "Steps 37400| Train Loss = 6.8505425453186035| Val acc = 0.8483333333333334\n",
            "Steps 37500| Train Loss = 8.087911605834961| Val acc = 0.8486666666666667\n",
            "Steps 37600| Train Loss = 10.775189399719238| Val acc = 0.8496666666666667\n",
            "Steps 37700| Train Loss = 13.77961540222168| Val acc = 0.8516666666666667\n",
            "Steps 37800| Train Loss = 11.241451263427734| Val acc = 0.8496666666666667\n",
            "Steps 37900| Train Loss = 13.441633224487305| Val acc = 0.847\n",
            "Steps 38000| Train Loss = 9.041078567504883| Val acc = 0.8426666666666667\n",
            "Steps 38100| Train Loss = 7.7209625244140625| Val acc = 0.849\n",
            "Steps 38200| Train Loss = 7.53353214263916| Val acc = 0.8483333333333334\n",
            "Steps 38300| Train Loss = 5.866354942321777| Val acc = 0.8493333333333334\n",
            "Steps 38400| Train Loss = 4.293430328369141| Val acc = 0.8443333333333334\n",
            "Steps 38500| Train Loss = 12.681048393249512| Val acc = 0.8506666666666667\n",
            "Steps 38600| Train Loss = 9.603626251220703| Val acc = 0.8486666666666667\n",
            "Steps 38700| Train Loss = 8.774706840515137| Val acc = 0.8506666666666667\n",
            "Steps 38800| Train Loss = 7.9490766525268555| Val acc = 0.8483333333333334\n",
            "Steps 38900| Train Loss = 8.245047569274902| Val acc = 0.851\n",
            "Steps 39000| Train Loss = 20.180740356445312| Val acc = 0.8496666666666667\n",
            "Steps 39100| Train Loss = 13.499814987182617| Val acc = 0.8466666666666667\n",
            "Steps 39200| Train Loss = 10.32750129699707| Val acc = 0.849\n",
            "Steps 39300| Train Loss = 2.96799635887146| Val acc = 0.8496666666666667\n",
            "Steps 39400| Train Loss = 13.789231300354004| Val acc = 0.847\n",
            "Steps 39500| Train Loss = 9.909210205078125| Val acc = 0.8506666666666667\n",
            "Steps 39600| Train Loss = 11.961410522460938| Val acc = 0.8483333333333334\n",
            "Steps 39700| Train Loss = 11.352993965148926| Val acc = 0.8476666666666667\n",
            "Steps 39800| Train Loss = 6.831647872924805| Val acc = 0.848\n",
            "Steps 39900| Train Loss = 8.702342987060547| Val acc = 0.8443333333333334\n",
            "Steps 40000| Train Loss = 4.579987525939941| Val acc = 0.8476666666666667\n",
            "Steps 40100| Train Loss = 4.801657676696777| Val acc = 0.848\n",
            "Steps 40200| Train Loss = 9.665534973144531| Val acc = 0.8473333333333334\n",
            "Steps 40300| Train Loss = 5.251099586486816| Val acc = 0.8513333333333334\n",
            "Steps 40400| Train Loss = 7.844379425048828| Val acc = 0.8513333333333334\n",
            "Steps 40500| Train Loss = 16.644775390625| Val acc = 0.8503333333333334\n",
            "Steps 40600| Train Loss = 14.110336303710938| Val acc = 0.8476666666666667\n",
            "Steps 40700| Train Loss = 10.244585037231445| Val acc = 0.8476666666666667\n",
            "Steps 40800| Train Loss = 10.212093353271484| Val acc = 0.854\n",
            "model saved to best.ckpt\n",
            "Steps 40900| Train Loss = 3.605562686920166| Val acc = 0.8483333333333334\n",
            "Steps 41000| Train Loss = 14.63215160369873| Val acc = 0.8356666666666667\n",
            "Steps 41100| Train Loss = 8.954452514648438| Val acc = 0.8496666666666667\n",
            "Steps 41200| Train Loss = 8.040700912475586| Val acc = 0.8473333333333334\n",
            "Steps 41300| Train Loss = 6.027042865753174| Val acc = 0.848\n",
            "Steps 41400| Train Loss = 5.375112056732178| Val acc = 0.8456666666666667\n",
            "Steps 41500| Train Loss = 11.501672744750977| Val acc = 0.8486666666666667\n",
            "Steps 41600| Train Loss = 15.18221664428711| Val acc = 0.849\n",
            "Steps 41700| Train Loss = 7.206140041351318| Val acc = 0.8476666666666667\n",
            "Steps 41800| Train Loss = 7.129530429840088| Val acc = 0.8476666666666667\n",
            "Steps 41900| Train Loss = 11.328990936279297| Val acc = 0.8526666666666667\n",
            "Steps 42000| Train Loss = 12.190089225769043| Val acc = 0.8466666666666667\n",
            "Steps 42100| Train Loss = 11.756509780883789| Val acc = 0.8476666666666667\n",
            "Steps 42200| Train Loss = 6.7527947425842285| Val acc = 0.8483333333333334\n",
            "Steps 42300| Train Loss = 6.768630027770996| Val acc = 0.8463333333333334\n",
            "Steps 42400| Train Loss = 10.644055366516113| Val acc = 0.8463333333333334\n",
            "Steps 42500| Train Loss = 9.86633586883545| Val acc = 0.8476666666666667\n",
            "Steps 42600| Train Loss = 14.504987716674805| Val acc = 0.848\n",
            "Steps 42700| Train Loss = 6.083808898925781| Val acc = 0.8463333333333334\n",
            "Steps 42800| Train Loss = 7.617369651794434| Val acc = 0.8486666666666667\n",
            "Steps 42900| Train Loss = 6.246217727661133| Val acc = 0.851\n",
            "Steps 43000| Train Loss = 11.556297302246094| Val acc = 0.8473333333333334\n",
            "Steps 43100| Train Loss = 10.133386611938477| Val acc = 0.851\n",
            "Steps 43200| Train Loss = 12.060628890991211| Val acc = 0.8486666666666667\n",
            "Steps 43300| Train Loss = 16.89178466796875| Val acc = 0.8506666666666667\n",
            "Steps 43400| Train Loss = 7.225893020629883| Val acc = 0.8476666666666667\n",
            "Steps 43500| Train Loss = 8.749390602111816| Val acc = 0.8516666666666667\n",
            "Steps 43600| Train Loss = 5.87501859664917| Val acc = 0.8546666666666667\n",
            "model saved to best.ckpt\n",
            "Steps 43700| Train Loss = 9.270469665527344| Val acc = 0.85\n",
            "Steps 43800| Train Loss = 11.34691047668457| Val acc = 0.8496666666666667\n",
            "Steps 43900| Train Loss = 10.245677947998047| Val acc = 0.8493333333333334\n",
            "Steps 44000| Train Loss = 8.279778480529785| Val acc = 0.8473333333333334\n",
            "Steps 44100| Train Loss = 5.633949279785156| Val acc = 0.8476666666666667\n",
            "Steps 44200| Train Loss = 1.8028383255004883| Val acc = 0.8466666666666667\n",
            "Steps 44300| Train Loss = 19.33175277709961| Val acc = 0.848\n",
            "Steps 44400| Train Loss = 8.841304779052734| Val acc = 0.8423333333333334\n",
            "Steps 44500| Train Loss = 16.26312255859375| Val acc = 0.847\n",
            "Steps 44600| Train Loss = 9.598173141479492| Val acc = 0.848\n",
            "Steps 44700| Train Loss = 7.000244140625| Val acc = 0.849\n",
            "Steps 44800| Train Loss = 11.248886108398438| Val acc = 0.851\n",
            "Steps 44900| Train Loss = 7.656416893005371| Val acc = 0.8503333333333334\n",
            "Steps 45000| Train Loss = 15.828268051147461| Val acc = 0.848\n",
            "Steps 45100| Train Loss = 6.32722282409668| Val acc = 0.846\n",
            "Steps 45200| Train Loss = 3.3864355087280273| Val acc = 0.845\n",
            "Steps 45300| Train Loss = 14.238408088684082| Val acc = 0.8436666666666667\n",
            "Steps 45400| Train Loss = 8.335240364074707| Val acc = 0.8446666666666667\n",
            "Steps 45500| Train Loss = 18.757104873657227| Val acc = 0.849\n",
            "Steps 45600| Train Loss = 13.456911087036133| Val acc = 0.8493333333333334\n",
            "Steps 45700| Train Loss = 9.45616340637207| Val acc = 0.851\n",
            "Steps 45800| Train Loss = 9.41049575805664| Val acc = 0.8486666666666667\n",
            "Steps 45900| Train Loss = 10.80571174621582| Val acc = 0.8513333333333334\n",
            "Steps 46000| Train Loss = 14.709457397460938| Val acc = 0.8433333333333334\n",
            "Steps 46100| Train Loss = 9.035008430480957| Val acc = 0.849\n",
            "Steps 46200| Train Loss = 8.941675186157227| Val acc = 0.849\n",
            "Steps 46300| Train Loss = 17.400489807128906| Val acc = 0.8496666666666667\n",
            "Steps 46400| Train Loss = 14.548835754394531| Val acc = 0.8486666666666667\n",
            "Steps 46500| Train Loss = 16.052186965942383| Val acc = 0.8503333333333334\n",
            "Steps 46600| Train Loss = 2.7047362327575684| Val acc = 0.8526666666666667\n",
            "Steps 46700| Train Loss = 4.270595550537109| Val acc = 0.8493333333333334\n",
            "Steps 46800| Train Loss = 7.3976240158081055| Val acc = 0.8466666666666667\n",
            "Steps 46900| Train Loss = 3.5270986557006836| Val acc = 0.851\n",
            "Steps 47000| Train Loss = 18.089065551757812| Val acc = 0.849\n",
            "Steps 47100| Train Loss = 5.388103008270264| Val acc = 0.848\n",
            "Steps 47200| Train Loss = 8.310986518859863| Val acc = 0.8483333333333334\n",
            "Steps 47300| Train Loss = 17.413429260253906| Val acc = 0.8443333333333334\n",
            "Steps 47400| Train Loss = 5.689109802246094| Val acc = 0.8476666666666667\n",
            "Steps 47500| Train Loss = 8.360845565795898| Val acc = 0.8486666666666667\n",
            "Steps 47600| Train Loss = 11.063430786132812| Val acc = 0.848\n",
            "Steps 47700| Train Loss = 5.546724319458008| Val acc = 0.852\n",
            "Steps 47800| Train Loss = 18.607873916625977| Val acc = 0.8523333333333334\n",
            "Steps 47900| Train Loss = 5.83318567276001| Val acc = 0.848\n",
            "Steps 48000| Train Loss = 18.3404483795166| Val acc = 0.852\n",
            "Steps 48100| Train Loss = 11.367128372192383| Val acc = 0.8496666666666667\n",
            "Steps 48200| Train Loss = 14.795348167419434| Val acc = 0.8493333333333334\n",
            "Steps 48300| Train Loss = 10.268030166625977| Val acc = 0.8526666666666667\n",
            "Steps 48400| Train Loss = 7.509700298309326| Val acc = 0.8523333333333334\n",
            "Steps 48500| Train Loss = 16.898643493652344| Val acc = 0.849\n",
            "Steps 48600| Train Loss = 11.993402481079102| Val acc = 0.8493333333333334\n",
            "Steps 48700| Train Loss = 6.297374725341797| Val acc = 0.8503333333333334\n",
            "Steps 48800| Train Loss = 17.22675323486328| Val acc = 0.8493333333333334\n",
            "Steps 48900| Train Loss = 6.179386138916016| Val acc = 0.846\n",
            "Steps 49000| Train Loss = 15.453432083129883| Val acc = 0.85\n",
            "Steps 49100| Train Loss = 12.99268913269043| Val acc = 0.8476666666666667\n",
            "Steps 49200| Train Loss = 4.260895252227783| Val acc = 0.853\n",
            "Steps 49300| Train Loss = 8.113565444946289| Val acc = 0.8486666666666667\n",
            "Steps 49400| Train Loss = 16.117237091064453| Val acc = 0.8473333333333334\n",
            "Steps 49500| Train Loss = 8.272767066955566| Val acc = 0.8526666666666667\n",
            "Steps 49600| Train Loss = 12.523468017578125| Val acc = 0.848\n",
            "Steps 49700| Train Loss = 9.396570205688477| Val acc = 0.8486666666666667\n",
            "Steps 49800| Train Loss = 11.64124870300293| Val acc = 0.849\n",
            "Steps 49900| Train Loss = 12.182363510131836| Val acc = 0.8486666666666667\n",
            "Steps 50000| Train Loss = 13.026822090148926| Val acc = 0.8496666666666667\n",
            "Steps 50100| Train Loss = 15.79372501373291| Val acc = 0.849\n",
            "Steps 50200| Train Loss = 8.569812774658203| Val acc = 0.85\n",
            "Steps 50300| Train Loss = 13.378450393676758| Val acc = 0.8496666666666667\n",
            "Steps 50400| Train Loss = 11.099878311157227| Val acc = 0.848\n",
            "Steps 50500| Train Loss = 4.083764553070068| Val acc = 0.8503333333333334\n",
            "Steps 50600| Train Loss = 7.163419246673584| Val acc = 0.8513333333333334\n",
            "Steps 50700| Train Loss = 17.573198318481445| Val acc = 0.8276666666666667\n",
            "Steps 50800| Train Loss = 9.199980735778809| Val acc = 0.848\n",
            "Steps 50900| Train Loss = 11.116353034973145| Val acc = 0.852\n",
            "Steps 51000| Train Loss = 9.448305130004883| Val acc = 0.848\n",
            "Steps 51100| Train Loss = 16.232908248901367| Val acc = 0.847\n",
            "Steps 51200| Train Loss = 9.666425704956055| Val acc = 0.85\n",
            "Steps 51300| Train Loss = 5.601300239562988| Val acc = 0.8466666666666667\n",
            "Steps 51400| Train Loss = 4.729840278625488| Val acc = 0.849\n",
            "Steps 51500| Train Loss = 10.084943771362305| Val acc = 0.8493333333333334\n",
            "Steps 51600| Train Loss = 12.012950897216797| Val acc = 0.8516666666666667\n",
            "Steps 51700| Train Loss = 8.918359756469727| Val acc = 0.8476666666666667\n",
            "Steps 51800| Train Loss = 9.776762008666992| Val acc = 0.8476666666666667\n",
            "Steps 51900| Train Loss = 19.33389663696289| Val acc = 0.8486666666666667\n",
            "Steps 52000| Train Loss = 4.18208646774292| Val acc = 0.8463333333333334\n",
            "Steps 52100| Train Loss = 17.246421813964844| Val acc = 0.853\n",
            "Steps 52200| Train Loss = 7.458697319030762| Val acc = 0.851\n",
            "Steps 52300| Train Loss = 6.894801616668701| Val acc = 0.8516666666666667\n",
            "Steps 52400| Train Loss = 7.943687438964844| Val acc = 0.837\n",
            "Steps 52500| Train Loss = 5.041201591491699| Val acc = 0.8446666666666667\n",
            "Steps 52600| Train Loss = 12.328927993774414| Val acc = 0.8496666666666667\n",
            "Steps 52700| Train Loss = 9.87712287902832| Val acc = 0.8526666666666667\n",
            "Steps 52800| Train Loss = 12.822526931762695| Val acc = 0.8506666666666667\n",
            "Steps 52900| Train Loss = 10.75839614868164| Val acc = 0.8493333333333334\n",
            "Steps 53000| Train Loss = 12.236133575439453| Val acc = 0.851\n",
            "Steps 53100| Train Loss = 5.219444751739502| Val acc = 0.8476666666666667\n",
            "Steps 53200| Train Loss = 11.79592514038086| Val acc = 0.8486666666666667\n",
            "Steps 53300| Train Loss = 3.0120575428009033| Val acc = 0.8486666666666667\n",
            "Steps 53400| Train Loss = 13.139189720153809| Val acc = 0.8473333333333334\n",
            "Steps 53500| Train Loss = 5.1994099617004395| Val acc = 0.8476666666666667\n",
            "Steps 53600| Train Loss = 12.339008331298828| Val acc = 0.8503333333333334\n",
            "Steps 53700| Train Loss = 7.395450592041016| Val acc = 0.8486666666666667\n",
            "Steps 53800| Train Loss = 10.045693397521973| Val acc = 0.8466666666666667\n",
            "Steps 53900| Train Loss = 14.863832473754883| Val acc = 0.8466666666666667\n",
            "Steps 54000| Train Loss = 6.295840263366699| Val acc = 0.8463333333333334\n",
            "Steps 54100| Train Loss = 9.689102172851562| Val acc = 0.8486666666666667\n",
            "Steps 54200| Train Loss = 19.97698211669922| Val acc = 0.851\n",
            "Steps 54300| Train Loss = 11.054786682128906| Val acc = 0.8476666666666667\n",
            "Steps 54400| Train Loss = 11.157255172729492| Val acc = 0.848\n",
            "Steps 54500| Train Loss = 10.121600151062012| Val acc = 0.8463333333333334\n",
            "Steps 54600| Train Loss = 8.543163299560547| Val acc = 0.846\n",
            "Steps 54700| Train Loss = 6.918335914611816| Val acc = 0.8476666666666667\n",
            "Steps 54800| Train Loss = 6.862527370452881| Val acc = 0.8516666666666667\n",
            "Steps 54900| Train Loss = 4.799802303314209| Val acc = 0.8473333333333334\n",
            "Steps 55000| Train Loss = 19.291034698486328| Val acc = 0.8503333333333334\n",
            "Steps 55100| Train Loss = 9.722709655761719| Val acc = 0.85\n",
            "Steps 55200| Train Loss = 12.496313095092773| Val acc = 0.8483333333333334\n",
            "Steps 55300| Train Loss = 18.288454055786133| Val acc = 0.851\n",
            "Steps 55400| Train Loss = 8.365182876586914| Val acc = 0.851\n",
            "Steps 55500| Train Loss = 12.647468566894531| Val acc = 0.847\n",
            "Steps 55600| Train Loss = 11.117246627807617| Val acc = 0.848\n",
            "Steps 55700| Train Loss = 9.148778915405273| Val acc = 0.8486666666666667\n",
            "Steps 55800| Train Loss = 9.89459228515625| Val acc = 0.85\n",
            "Steps 55900| Train Loss = 1.6510460376739502| Val acc = 0.8506666666666667\n",
            "Steps 56000| Train Loss = 7.579753875732422| Val acc = 0.8496666666666667\n",
            "Steps 56100| Train Loss = 8.188657760620117| Val acc = 0.842\n",
            "Steps 56200| Train Loss = 9.814298629760742| Val acc = 0.8486666666666667\n",
            "Steps 56300| Train Loss = 4.681307792663574| Val acc = 0.8513333333333334\n",
            "Steps 56400| Train Loss = 9.276168823242188| Val acc = 0.8466666666666667\n",
            "Steps 56500| Train Loss = 11.63325309753418| Val acc = 0.8483333333333334\n",
            "Steps 56600| Train Loss = 5.724092960357666| Val acc = 0.852\n",
            "Steps 56700| Train Loss = 28.91299819946289| Val acc = 0.8513333333333334\n",
            "Steps 56800| Train Loss = 9.78091049194336| Val acc = 0.846\n",
            "Steps 56900| Train Loss = 4.906771183013916| Val acc = 0.8496666666666667\n",
            "Steps 57000| Train Loss = 12.712108612060547| Val acc = 0.85\n",
            "Steps 57100| Train Loss = 9.20363712310791| Val acc = 0.8473333333333334\n",
            "Steps 57200| Train Loss = 10.58116340637207| Val acc = 0.852\n",
            "Steps 57300| Train Loss = 7.609394550323486| Val acc = 0.8476666666666667\n",
            "Steps 57400| Train Loss = 10.569252967834473| Val acc = 0.8506666666666667\n",
            "Steps 57500| Train Loss = 10.378679275512695| Val acc = 0.8463333333333334\n",
            "Steps 57600| Train Loss = 9.108209609985352| Val acc = 0.85\n",
            "Steps 57700| Train Loss = 7.61094856262207| Val acc = 0.848\n",
            "Steps 57800| Train Loss = 6.885256290435791| Val acc = 0.8483333333333334\n",
            "Steps 57900| Train Loss = 3.2371649742126465| Val acc = 0.8476666666666667\n",
            "Steps 58000| Train Loss = 3.1664505004882812| Val acc = 0.8476666666666667\n",
            "Steps 58100| Train Loss = 11.139809608459473| Val acc = 0.8476666666666667\n",
            "Steps 58200| Train Loss = 8.933130264282227| Val acc = 0.846\n",
            "Steps 58300| Train Loss = 9.691072463989258| Val acc = 0.8476666666666667\n",
            "Steps 58400| Train Loss = 5.184360980987549| Val acc = 0.8486666666666667\n",
            "Steps 58500| Train Loss = 15.007293701171875| Val acc = 0.8486666666666667\n",
            "Steps 58600| Train Loss = 11.942770004272461| Val acc = 0.8486666666666667\n",
            "Steps 58700| Train Loss = 8.486200332641602| Val acc = 0.8476666666666667\n",
            "Steps 58800| Train Loss = 12.270103454589844| Val acc = 0.8483333333333334\n",
            "Steps 58900| Train Loss = 9.48286247253418| Val acc = 0.8473333333333334\n",
            "Steps 59000| Train Loss = 15.311956405639648| Val acc = 0.849\n",
            "Steps 59100| Train Loss = 8.047130584716797| Val acc = 0.849\n",
            "Steps 59200| Train Loss = 10.226335525512695| Val acc = 0.849\n",
            "Steps 59300| Train Loss = 9.431964874267578| Val acc = 0.847\n",
            "Steps 59400| Train Loss = 5.520339012145996| Val acc = 0.8473333333333334\n",
            "Steps 59500| Train Loss = 4.746645927429199| Val acc = 0.8476666666666667\n",
            "Steps 59600| Train Loss = 2.5730278491973877| Val acc = 0.848\n",
            "Steps 59700| Train Loss = 7.266040802001953| Val acc = 0.848\n",
            "Steps 59800| Train Loss = 9.472917556762695| Val acc = 0.8483333333333334\n",
            "Steps 59900| Train Loss = 19.271484375| Val acc = 0.8473333333333334\n",
            "Steps 60000| Train Loss = 11.907236099243164| Val acc = 0.8483333333333334\n",
            "Steps 60100| Train Loss = 9.230247497558594| Val acc = 0.8463333333333334\n",
            "Steps 60200| Train Loss = 7.6939496994018555| Val acc = 0.8486666666666667\n",
            "Steps 60300| Train Loss = 8.938943862915039| Val acc = 0.8466666666666667\n",
            "Steps 60400| Train Loss = 12.547857284545898| Val acc = 0.849\n",
            "Steps 60500| Train Loss = 11.10936164855957| Val acc = 0.8486666666666667\n",
            "Steps 60600| Train Loss = 17.865217208862305| Val acc = 0.8466666666666667\n",
            "Steps 60700| Train Loss = 5.727593898773193| Val acc = 0.8483333333333334\n",
            "Steps 60800| Train Loss = 15.230318069458008| Val acc = 0.8496666666666667\n",
            "Steps 60900| Train Loss = 6.896911144256592| Val acc = 0.847\n",
            "Steps 61000| Train Loss = 16.499364852905273| Val acc = 0.8466666666666667\n",
            "Steps 61100| Train Loss = 15.223978996276855| Val acc = 0.8483333333333334\n",
            "Steps 61200| Train Loss = 9.239509582519531| Val acc = 0.847\n",
            "Steps 61300| Train Loss = 8.68769359588623| Val acc = 0.8476666666666667\n",
            "Steps 61400| Train Loss = 4.6914753913879395| Val acc = 0.847\n",
            "Steps 61500| Train Loss = 16.690122604370117| Val acc = 0.849\n",
            "Steps 61600| Train Loss = 8.996164321899414| Val acc = 0.8453333333333334\n",
            "Steps 61700| Train Loss = 4.0362629890441895| Val acc = 0.848\n",
            "Steps 61800| Train Loss = 3.763169050216675| Val acc = 0.8493333333333334\n",
            "Steps 61900| Train Loss = 13.727352142333984| Val acc = 0.8473333333333334\n",
            "Steps 62000| Train Loss = 13.131077766418457| Val acc = 0.8496666666666667\n",
            "Steps 62100| Train Loss = 12.706283569335938| Val acc = 0.8516666666666667\n",
            "Steps 62200| Train Loss = 4.614538669586182| Val acc = 0.8493333333333334\n",
            "Steps 62300| Train Loss = 1.8790733814239502| Val acc = 0.8476666666666667\n",
            "Steps 62400| Train Loss = 11.47372817993164| Val acc = 0.8473333333333334\n",
            "Steps 62500| Train Loss = 10.081303596496582| Val acc = 0.849\n",
            "Steps 62600| Train Loss = 7.844966888427734| Val acc = 0.848\n",
            "Steps 62700| Train Loss = 6.263411998748779| Val acc = 0.8496666666666667\n",
            "Steps 62800| Train Loss = 4.677165985107422| Val acc = 0.849\n",
            "Steps 62900| Train Loss = 6.80811071395874| Val acc = 0.8476666666666667\n",
            "Steps 63000| Train Loss = 12.043464660644531| Val acc = 0.8496666666666667\n",
            "Steps 63100| Train Loss = 12.17600154876709| Val acc = 0.849\n",
            "Steps 63200| Train Loss = 13.388437271118164| Val acc = 0.8433333333333334\n",
            "Steps 63300| Train Loss = 8.257205963134766| Val acc = 0.8466666666666667\n",
            "Steps 63400| Train Loss = 6.763798236846924| Val acc = 0.847\n",
            "Steps 63500| Train Loss = 12.220699310302734| Val acc = 0.847\n",
            "Steps 63600| Train Loss = 10.911972045898438| Val acc = 0.849\n",
            "Steps 63700| Train Loss = 13.078393936157227| Val acc = 0.8483333333333334\n",
            "Steps 63800| Train Loss = 9.26876449584961| Val acc = 0.85\n",
            "Steps 63900| Train Loss = 10.178163528442383| Val acc = 0.8496666666666667\n",
            "Steps 64000| Train Loss = 13.5848970413208| Val acc = 0.852\n",
            "Steps 64100| Train Loss = 15.415177345275879| Val acc = 0.851\n",
            "Steps 64200| Train Loss = 11.456399917602539| Val acc = 0.849\n",
            "Steps 64300| Train Loss = 6.293296813964844| Val acc = 0.8496666666666667\n",
            "Steps 64400| Train Loss = 14.43179702758789| Val acc = 0.8503333333333334\n",
            "Steps 64500| Train Loss = 7.215252876281738| Val acc = 0.8403333333333334\n",
            "Steps 64600| Train Loss = 6.749253273010254| Val acc = 0.849\n",
            "Steps 64700| Train Loss = 8.293745994567871| Val acc = 0.8503333333333334\n",
            "Steps 64800| Train Loss = 9.290779113769531| Val acc = 0.8486666666666667\n",
            "Steps 64900| Train Loss = 12.931361198425293| Val acc = 0.8453333333333334\n",
            "Steps 65000| Train Loss = 8.184097290039062| Val acc = 0.848\n",
            "Steps 65100| Train Loss = 9.59276008605957| Val acc = 0.8473333333333334\n",
            "Steps 65200| Train Loss = 5.389770984649658| Val acc = 0.8516666666666667\n",
            "Steps 65300| Train Loss = 10.708498001098633| Val acc = 0.8486666666666667\n",
            "Steps 65400| Train Loss = 8.13208293914795| Val acc = 0.8483333333333334\n",
            "Steps 65500| Train Loss = 1.5483777523040771| Val acc = 0.8486666666666667\n",
            "Steps 65600| Train Loss = 4.294594764709473| Val acc = 0.8473333333333334\n",
            "Steps 65700| Train Loss = 11.558820724487305| Val acc = 0.8506666666666667\n",
            "Steps 65800| Train Loss = 11.192062377929688| Val acc = 0.8496666666666667\n",
            "Steps 65900| Train Loss = 17.965078353881836| Val acc = 0.8403333333333334\n",
            "Steps 66000| Train Loss = 6.7422404289245605| Val acc = 0.848\n",
            "Steps 66100| Train Loss = 3.629451036453247| Val acc = 0.8486666666666667\n",
            "Steps 66200| Train Loss = 12.205850601196289| Val acc = 0.8483333333333334\n",
            "Steps 66300| Train Loss = 11.3733549118042| Val acc = 0.849\n",
            "Steps 66400| Train Loss = 11.393966674804688| Val acc = 0.8476666666666667\n",
            "Steps 66500| Train Loss = 5.828807830810547| Val acc = 0.8496666666666667\n",
            "Steps 66600| Train Loss = 6.881939888000488| Val acc = 0.8503333333333334\n",
            "Steps 66700| Train Loss = 12.963197708129883| Val acc = 0.847\n",
            "Steps 66800| Train Loss = 9.842277526855469| Val acc = 0.8483333333333334\n",
            "Steps 66900| Train Loss = 13.820152282714844| Val acc = 0.8496666666666667\n",
            "Steps 67000| Train Loss = 10.51009464263916| Val acc = 0.849\n",
            "Steps 67100| Train Loss = 13.904821395874023| Val acc = 0.8486666666666667\n",
            "Steps 67200| Train Loss = 9.689697265625| Val acc = 0.8496666666666667\n",
            "Steps 67300| Train Loss = 12.133769035339355| Val acc = 0.8493333333333334\n",
            "Steps 67400| Train Loss = 12.288359642028809| Val acc = 0.8496666666666667\n",
            "Steps 67500| Train Loss = 19.30975341796875| Val acc = 0.8483333333333334\n",
            "Steps 67600| Train Loss = 16.546955108642578| Val acc = 0.8486666666666667\n",
            "Steps 67700| Train Loss = 14.353583335876465| Val acc = 0.8463333333333334\n",
            "Steps 67800| Train Loss = 7.2392425537109375| Val acc = 0.8486666666666667\n",
            "Steps 67900| Train Loss = 12.317977905273438| Val acc = 0.848\n",
            "Steps 68000| Train Loss = 9.262068748474121| Val acc = 0.8493333333333334\n",
            "Steps 68100| Train Loss = 8.183754920959473| Val acc = 0.8513333333333334\n",
            "Steps 68200| Train Loss = 3.7931137084960938| Val acc = 0.8516666666666667\n",
            "Steps 68300| Train Loss = 6.076109886169434| Val acc = 0.8516666666666667\n",
            "Steps 68400| Train Loss = 6.932940483093262| Val acc = 0.8463333333333334\n",
            "Steps 68500| Train Loss = 6.5005316734313965| Val acc = 0.8523333333333334\n",
            "Steps 68600| Train Loss = 15.656893730163574| Val acc = 0.847\n",
            "Steps 68700| Train Loss = 1.9863592386245728| Val acc = 0.851\n",
            "Steps 68800| Train Loss = 9.930261611938477| Val acc = 0.8476666666666667\n",
            "Steps 68900| Train Loss = 15.022797584533691| Val acc = 0.8496666666666667\n",
            "Steps 69000| Train Loss = 14.789483070373535| Val acc = 0.8483333333333334\n",
            "Steps 69100| Train Loss = 25.47903060913086| Val acc = 0.8526666666666667\n",
            "Steps 69200| Train Loss = 8.88313102722168| Val acc = 0.8516666666666667\n",
            "Steps 69300| Train Loss = 6.226491451263428| Val acc = 0.8486666666666667\n",
            "Steps 69400| Train Loss = 5.958294868469238| Val acc = 0.851\n",
            "Steps 69500| Train Loss = 12.928533554077148| Val acc = 0.8503333333333334\n",
            "Steps 69600| Train Loss = 3.6102747917175293| Val acc = 0.8486666666666667\n",
            "Steps 69700| Train Loss = 13.049783706665039| Val acc = 0.8513333333333334\n",
            "Steps 69800| Train Loss = 5.095691680908203| Val acc = 0.8513333333333334\n",
            "Steps 69900| Train Loss = 13.02994155883789| Val acc = 0.8526666666666667\n",
            "Steps 70000| Train Loss = 9.225112915039062| Val acc = 0.8536666666666667\n",
            "Steps 70100| Train Loss = 16.083463668823242| Val acc = 0.8496666666666667\n",
            "Steps 70200| Train Loss = 17.346363067626953| Val acc = 0.852\n",
            "Steps 70300| Train Loss = 11.21015739440918| Val acc = 0.85\n",
            "Steps 70400| Train Loss = 11.013257026672363| Val acc = 0.8503333333333334\n",
            "Steps 70500| Train Loss = 11.040969848632812| Val acc = 0.85\n",
            "Steps 70600| Train Loss = 11.854351043701172| Val acc = 0.851\n",
            "Steps 70700| Train Loss = 19.200790405273438| Val acc = 0.8493333333333334\n",
            "Steps 70800| Train Loss = 3.803542375564575| Val acc = 0.8463333333333334\n",
            "Steps 70900| Train Loss = 13.03000545501709| Val acc = 0.8513333333333334\n",
            "Steps 71000| Train Loss = 4.854852676391602| Val acc = 0.8526666666666667\n",
            "Steps 71100| Train Loss = 9.420428276062012| Val acc = 0.8516666666666667\n",
            "Steps 71200| Train Loss = 8.819655418395996| Val acc = 0.8536666666666667\n",
            "Steps 71300| Train Loss = 8.84762191772461| Val acc = 0.8513333333333334\n",
            "Steps 71400| Train Loss = 7.220782279968262| Val acc = 0.8413333333333334\n",
            "Steps 71500| Train Loss = 16.83066177368164| Val acc = 0.8503333333333334\n",
            "Steps 71600| Train Loss = 5.9499640464782715| Val acc = 0.846\n",
            "Steps 71700| Train Loss = 8.733720779418945| Val acc = 0.8496666666666667\n",
            "Steps 71800| Train Loss = 11.232179641723633| Val acc = 0.8503333333333334\n",
            "Steps 71900| Train Loss = 11.330731391906738| Val acc = 0.8496666666666667\n",
            "Steps 72000| Train Loss = 6.038564205169678| Val acc = 0.8483333333333334\n",
            "Steps 72100| Train Loss = 12.390934944152832| Val acc = 0.8503333333333334\n",
            "Steps 72200| Train Loss = 9.179593086242676| Val acc = 0.8473333333333334\n",
            "Steps 72300| Train Loss = 4.763123989105225| Val acc = 0.851\n",
            "Steps 72400| Train Loss = 6.7636919021606445| Val acc = 0.8466666666666667\n",
            "Steps 72500| Train Loss = 7.556956768035889| Val acc = 0.8526666666666667\n",
            "Steps 72600| Train Loss = 9.014591217041016| Val acc = 0.848\n",
            "Steps 72700| Train Loss = 17.027332305908203| Val acc = 0.8316666666666667\n",
            "Steps 72800| Train Loss = 7.428778648376465| Val acc = 0.8443333333333334\n",
            "Steps 72900| Train Loss = 4.577706336975098| Val acc = 0.849\n",
            "Steps 73000| Train Loss = 9.514997482299805| Val acc = 0.848\n",
            "Steps 73100| Train Loss = 8.049400329589844| Val acc = 0.8476666666666667\n",
            "Steps 73200| Train Loss = 5.814198970794678| Val acc = 0.8506666666666667\n",
            "Steps 73300| Train Loss = 5.212203502655029| Val acc = 0.853\n",
            "Steps 73400| Train Loss = 9.463661193847656| Val acc = 0.847\n",
            "Steps 73500| Train Loss = 9.689912796020508| Val acc = 0.8506666666666667\n",
            "Steps 73600| Train Loss = 8.602241516113281| Val acc = 0.8506666666666667\n",
            "Steps 73700| Train Loss = 5.270963191986084| Val acc = 0.8496666666666667\n",
            "Steps 73800| Train Loss = 20.556110382080078| Val acc = 0.8493333333333334\n",
            "Steps 73900| Train Loss = 6.196234703063965| Val acc = 0.8293333333333334\n",
            "Steps 74000| Train Loss = 7.28590202331543| Val acc = 0.849\n",
            "Steps 74100| Train Loss = 13.583534240722656| Val acc = 0.8503333333333334\n",
            "Steps 74200| Train Loss = 6.64766263961792| Val acc = 0.8523333333333334\n",
            "Steps 74300| Train Loss = 6.688018321990967| Val acc = 0.8473333333333334\n",
            "Steps 74400| Train Loss = 8.07246208190918| Val acc = 0.851\n",
            "Steps 74500| Train Loss = 11.628938674926758| Val acc = 0.8476666666666667\n",
            "Steps 74600| Train Loss = 5.100927829742432| Val acc = 0.85\n",
            "Steps 74700| Train Loss = 12.620824813842773| Val acc = 0.85\n",
            "Steps 74800| Train Loss = 1.0361957550048828| Val acc = 0.8473333333333334\n",
            "Steps 74900| Train Loss = 5.618088245391846| Val acc = 0.8516666666666667\n",
            "Steps 75000| Train Loss = 16.386573791503906| Val acc = 0.841\n",
            "Steps 75100| Train Loss = 13.67276382446289| Val acc = 0.851\n",
            "Steps 75200| Train Loss = 9.500450134277344| Val acc = 0.85\n",
            "Steps 75300| Train Loss = 11.521800994873047| Val acc = 0.8476666666666667\n",
            "Steps 75400| Train Loss = 16.862520217895508| Val acc = 0.8513333333333334\n",
            "Steps 75500| Train Loss = 9.665267944335938| Val acc = 0.8503333333333334\n",
            "Steps 75600| Train Loss = 14.842292785644531| Val acc = 0.846\n",
            "Steps 75700| Train Loss = 7.2299604415893555| Val acc = 0.8503333333333334\n",
            "Steps 75800| Train Loss = 8.03055191040039| Val acc = 0.8476666666666667\n",
            "Steps 75900| Train Loss = 16.286632537841797| Val acc = 0.8493333333333334\n",
            "Steps 76000| Train Loss = 3.1382133960723877| Val acc = 0.8506666666666667\n",
            "Steps 76100| Train Loss = 9.76169204711914| Val acc = 0.845\n",
            "Steps 76200| Train Loss = 10.652095794677734| Val acc = 0.8476666666666667\n",
            "Steps 76300| Train Loss = 19.891071319580078| Val acc = 0.8503333333333334\n",
            "Steps 76400| Train Loss = 2.4362940788269043| Val acc = 0.85\n",
            "Steps 76500| Train Loss = 17.38427734375| Val acc = 0.8506666666666667\n",
            "Steps 76600| Train Loss = 3.5521342754364014| Val acc = 0.8503333333333334\n",
            "Steps 76700| Train Loss = 14.156265258789062| Val acc = 0.8476666666666667\n",
            "Steps 76800| Train Loss = 14.293107032775879| Val acc = 0.8496666666666667\n",
            "Steps 76900| Train Loss = 9.181737899780273| Val acc = 0.85\n",
            "Steps 77000| Train Loss = 15.235777854919434| Val acc = 0.85\n",
            "Steps 77100| Train Loss = 8.060518264770508| Val acc = 0.85\n",
            "Steps 77200| Train Loss = 3.3901162147521973| Val acc = 0.8506666666666667\n",
            "Steps 77300| Train Loss = 6.086095333099365| Val acc = 0.8483333333333334\n",
            "Steps 77400| Train Loss = 10.413850784301758| Val acc = 0.849\n",
            "Steps 77500| Train Loss = 13.439128875732422| Val acc = 0.8493333333333334\n",
            "Steps 77600| Train Loss = 14.442665100097656| Val acc = 0.85\n",
            "Steps 77700| Train Loss = 7.6412248611450195| Val acc = 0.8493333333333334\n",
            "Steps 77800| Train Loss = 14.119823455810547| Val acc = 0.851\n",
            "Steps 77900| Train Loss = 13.35608959197998| Val acc = 0.8503333333333334\n",
            "Steps 78000| Train Loss = 12.639976501464844| Val acc = 0.8506666666666667\n",
            "Steps 78100| Train Loss = 8.634671211242676| Val acc = 0.8496666666666667\n",
            "Steps 78200| Train Loss = 6.416143417358398| Val acc = 0.849\n",
            "Steps 78300| Train Loss = 8.684013366699219| Val acc = 0.8513333333333334\n",
            "Steps 78400| Train Loss = 9.63783073425293| Val acc = 0.852\n",
            "Steps 78500| Train Loss = 4.788562297821045| Val acc = 0.851\n",
            "Steps 78600| Train Loss = 9.892030715942383| Val acc = 0.849\n",
            "Steps 78700| Train Loss = 12.419520378112793| Val acc = 0.8503333333333334\n",
            "Steps 78800| Train Loss = 7.409397125244141| Val acc = 0.8503333333333334\n",
            "Steps 78900| Train Loss = 8.871286392211914| Val acc = 0.8516666666666667\n",
            "Steps 79000| Train Loss = 6.886547088623047| Val acc = 0.849\n",
            "Steps 79100| Train Loss = 6.125034809112549| Val acc = 0.849\n",
            "Steps 79200| Train Loss = 9.38994312286377| Val acc = 0.8506666666666667\n",
            "Steps 79300| Train Loss = 5.245640754699707| Val acc = 0.8493333333333334\n",
            "Steps 79400| Train Loss = 2.359837293624878| Val acc = 0.85\n",
            "Steps 79500| Train Loss = 6.379664897918701| Val acc = 0.8513333333333334\n",
            "Steps 79600| Train Loss = 11.10065746307373| Val acc = 0.8506666666666667\n",
            "Steps 79700| Train Loss = 9.515839576721191| Val acc = 0.852\n",
            "Steps 79800| Train Loss = 7.785449028015137| Val acc = 0.8493333333333334\n",
            "Steps 79900| Train Loss = 5.431214809417725| Val acc = 0.8523333333333334\n",
            "Steps 80000| Train Loss = 8.810169219970703| Val acc = 0.849\n",
            "Steps 80100| Train Loss = 9.470036506652832| Val acc = 0.8513333333333334\n",
            "Steps 80200| Train Loss = 8.434318542480469| Val acc = 0.85\n",
            "Steps 80300| Train Loss = 8.910552024841309| Val acc = 0.848\n",
            "Steps 80400| Train Loss = 13.700065612792969| Val acc = 0.848\n",
            "Steps 80500| Train Loss = 5.089968204498291| Val acc = 0.8516666666666667\n",
            "Steps 80600| Train Loss = 15.818933486938477| Val acc = 0.8523333333333334\n",
            "Steps 80700| Train Loss = 13.05683708190918| Val acc = 0.851\n",
            "Steps 80800| Train Loss = 8.743670463562012| Val acc = 0.8476666666666667\n",
            "Steps 80900| Train Loss = 10.790502548217773| Val acc = 0.8513333333333334\n",
            "Steps 81000| Train Loss = 11.923910140991211| Val acc = 0.852\n",
            "Steps 81100| Train Loss = 8.18187141418457| Val acc = 0.8483333333333334\n",
            "Steps 81200| Train Loss = 4.766243934631348| Val acc = 0.845\n",
            "Steps 81300| Train Loss = 11.910053253173828| Val acc = 0.8506666666666667\n",
            "Steps 81400| Train Loss = 6.675670623779297| Val acc = 0.8546666666666667\n",
            "Steps 81500| Train Loss = 11.840086936950684| Val acc = 0.8513333333333334\n",
            "Steps 81600| Train Loss = 5.502175331115723| Val acc = 0.8543333333333333\n",
            "Steps 81700| Train Loss = 9.897806167602539| Val acc = 0.8486666666666667\n",
            "Steps 81800| Train Loss = 8.626118659973145| Val acc = 0.8473333333333334\n",
            "Steps 81900| Train Loss = 16.052562713623047| Val acc = 0.852\n",
            "Steps 82000| Train Loss = 15.669451713562012| Val acc = 0.8483333333333334\n",
            "Steps 82100| Train Loss = 7.28338623046875| Val acc = 0.8493333333333334\n",
            "Steps 82200| Train Loss = 12.63041877746582| Val acc = 0.849\n",
            "Steps 82300| Train Loss = 15.52960205078125| Val acc = 0.851\n",
            "Steps 82400| Train Loss = 5.567620754241943| Val acc = 0.849\n",
            "Steps 82500| Train Loss = 18.683067321777344| Val acc = 0.8486666666666667\n",
            "Steps 82600| Train Loss = 9.19896125793457| Val acc = 0.8523333333333334\n",
            "Steps 82700| Train Loss = 9.47535514831543| Val acc = 0.8523333333333334\n",
            "Steps 82800| Train Loss = 22.60161590576172| Val acc = 0.8506666666666667\n",
            "Steps 82900| Train Loss = 9.610939979553223| Val acc = 0.8486666666666667\n",
            "Steps 83000| Train Loss = 12.725057601928711| Val acc = 0.8526666666666667\n",
            "Steps 83100| Train Loss = 6.917215347290039| Val acc = 0.8476666666666667\n",
            "Steps 83200| Train Loss = 5.861849308013916| Val acc = 0.8496666666666667\n",
            "Steps 83300| Train Loss = 6.436738967895508| Val acc = 0.8473333333333334\n",
            "Steps 83400| Train Loss = 3.548117160797119| Val acc = 0.849\n",
            "Steps 83500| Train Loss = 6.204242706298828| Val acc = 0.8493333333333334\n",
            "Steps 83600| Train Loss = 12.42325210571289| Val acc = 0.8506666666666667\n",
            "Steps 83700| Train Loss = 4.683256149291992| Val acc = 0.847\n",
            "Steps 83800| Train Loss = 8.970857620239258| Val acc = 0.8506666666666667\n",
            "Steps 83900| Train Loss = 9.520856857299805| Val acc = 0.8486666666666667\n",
            "Steps 84000| Train Loss = 6.974854469299316| Val acc = 0.8486666666666667\n",
            "Steps 84100| Train Loss = 8.172064781188965| Val acc = 0.8466666666666667\n",
            "Steps 84200| Train Loss = 13.297441482543945| Val acc = 0.848\n",
            "Steps 84300| Train Loss = 4.949220657348633| Val acc = 0.848\n",
            "Steps 84400| Train Loss = 11.467918395996094| Val acc = 0.849\n",
            "Steps 84500| Train Loss = 5.331210613250732| Val acc = 0.849\n",
            "Steps 84600| Train Loss = 5.863168716430664| Val acc = 0.8486666666666667\n",
            "Steps 84700| Train Loss = 13.05550765991211| Val acc = 0.8496666666666667\n",
            "Steps 84800| Train Loss = 17.910066604614258| Val acc = 0.8506666666666667\n",
            "Steps 84900| Train Loss = 11.214195251464844| Val acc = 0.8506666666666667\n",
            "Steps 85000| Train Loss = 16.06359100341797| Val acc = 0.8483333333333334\n",
            "Steps 85100| Train Loss = 6.396903991699219| Val acc = 0.8506666666666667\n",
            "Steps 85200| Train Loss = 6.884986877441406| Val acc = 0.8523333333333334\n",
            "Steps 85300| Train Loss = 10.900823593139648| Val acc = 0.8506666666666667\n",
            "Steps 85400| Train Loss = 8.846264839172363| Val acc = 0.8483333333333334\n",
            "Steps 85500| Train Loss = 12.852212905883789| Val acc = 0.8526666666666667\n",
            "Steps 85600| Train Loss = 12.160560607910156| Val acc = 0.853\n",
            "Steps 85700| Train Loss = 14.593297958374023| Val acc = 0.8533333333333334\n",
            "Steps 85800| Train Loss = 4.577488422393799| Val acc = 0.847\n",
            "Steps 85900| Train Loss = 9.339276313781738| Val acc = 0.8523333333333334\n",
            "Steps 86000| Train Loss = 10.483522415161133| Val acc = 0.853\n",
            "Steps 86100| Train Loss = 9.261680603027344| Val acc = 0.8473333333333334\n",
            "Steps 86200| Train Loss = 11.993572235107422| Val acc = 0.8523333333333334\n",
            "Steps 86300| Train Loss = 4.506549835205078| Val acc = 0.8476666666666667\n",
            "Steps 86400| Train Loss = 9.224031448364258| Val acc = 0.8523333333333334\n",
            "Steps 86500| Train Loss = 12.344354629516602| Val acc = 0.8486666666666667\n",
            "Steps 86600| Train Loss = 8.671430587768555| Val acc = 0.8483333333333334\n",
            "Steps 86700| Train Loss = 10.162097930908203| Val acc = 0.846\n",
            "Steps 86800| Train Loss = 15.011256217956543| Val acc = 0.8486666666666667\n",
            "Steps 86900| Train Loss = 14.868481636047363| Val acc = 0.848\n",
            "Steps 87000| Train Loss = 9.064312934875488| Val acc = 0.852\n",
            "Steps 87100| Train Loss = 6.808388710021973| Val acc = 0.849\n",
            "Steps 87200| Train Loss = 11.262357711791992| Val acc = 0.851\n",
            "Steps 87300| Train Loss = 15.394323348999023| Val acc = 0.8516666666666667\n",
            "Steps 87400| Train Loss = 22.393352508544922| Val acc = 0.8506666666666667\n",
            "Steps 87500| Train Loss = 15.785287857055664| Val acc = 0.8523333333333334\n",
            "Steps 87600| Train Loss = 6.471330642700195| Val acc = 0.8506666666666667\n",
            "Steps 87700| Train Loss = 13.317789077758789| Val acc = 0.8503333333333334\n",
            "Steps 87800| Train Loss = 10.426141738891602| Val acc = 0.851\n",
            "Steps 87900| Train Loss = 4.8913421630859375| Val acc = 0.8506666666666667\n",
            "Steps 88000| Train Loss = 10.457415580749512| Val acc = 0.8516666666666667\n",
            "Steps 88100| Train Loss = 4.83820104598999| Val acc = 0.8526666666666667\n",
            "Steps 88200| Train Loss = 9.278770446777344| Val acc = 0.8496666666666667\n",
            "Steps 88300| Train Loss = 18.316164016723633| Val acc = 0.8516666666666667\n",
            "Steps 88400| Train Loss = 6.577751159667969| Val acc = 0.851\n",
            "Steps 88500| Train Loss = 14.301660537719727| Val acc = 0.8506666666666667\n",
            "Steps 88600| Train Loss = 6.066208362579346| Val acc = 0.85\n",
            "Steps 88700| Train Loss = 4.466346740722656| Val acc = 0.8493333333333334\n",
            "Steps 88800| Train Loss = 13.139972686767578| Val acc = 0.8473333333333334\n",
            "Steps 88900| Train Loss = 7.895456314086914| Val acc = 0.8523333333333334\n",
            "Steps 89000| Train Loss = 19.970937728881836| Val acc = 0.8506666666666667\n",
            "Steps 89100| Train Loss = 7.544025421142578| Val acc = 0.8483333333333334\n",
            "Steps 89200| Train Loss = 9.38690185546875| Val acc = 0.8506666666666667\n",
            "Steps 89300| Train Loss = 6.161318302154541| Val acc = 0.849\n",
            "Steps 89400| Train Loss = 10.153411865234375| Val acc = 0.8483333333333334\n",
            "Steps 89500| Train Loss = 9.479642868041992| Val acc = 0.8503333333333334\n",
            "Steps 89600| Train Loss = 8.527776718139648| Val acc = 0.848\n",
            "Steps 89700| Train Loss = 8.061999320983887| Val acc = 0.8493333333333334\n",
            "Steps 89800| Train Loss = 7.567605972290039| Val acc = 0.8523333333333334\n",
            "Steps 89900| Train Loss = 8.583345413208008| Val acc = 0.8496666666666667\n",
            "Steps 90000| Train Loss = 6.77927303314209| Val acc = 0.8516666666666667\n",
            "Steps 90100| Train Loss = 9.746946334838867| Val acc = 0.8466666666666667\n",
            "Steps 90200| Train Loss = 10.925407409667969| Val acc = 0.8506666666666667\n",
            "Steps 90300| Train Loss = 2.052297592163086| Val acc = 0.851\n",
            "Steps 90400| Train Loss = 10.611339569091797| Val acc = 0.848\n",
            "Steps 90500| Train Loss = 5.60919189453125| Val acc = 0.847\n",
            "Steps 90600| Train Loss = 13.708761215209961| Val acc = 0.8473333333333334\n",
            "Steps 90700| Train Loss = 7.953405857086182| Val acc = 0.8483333333333334\n",
            "Steps 90800| Train Loss = 5.494894981384277| Val acc = 0.8523333333333334\n",
            "Steps 90900| Train Loss = 7.172042369842529| Val acc = 0.8513333333333334\n",
            "Steps 91000| Train Loss = 20.399877548217773| Val acc = 0.847\n",
            "Steps 91100| Train Loss = 14.593326568603516| Val acc = 0.847\n",
            "Steps 91200| Train Loss = 12.36001968383789| Val acc = 0.849\n",
            "Steps 91300| Train Loss = 5.3420820236206055| Val acc = 0.8553333333333333\n",
            "model saved to best.ckpt\n",
            "Steps 91400| Train Loss = 4.067634105682373| Val acc = 0.852\n",
            "Steps 91500| Train Loss = 9.212343215942383| Val acc = 0.8506666666666667\n",
            "Steps 91600| Train Loss = 17.61296844482422| Val acc = 0.849\n",
            "Steps 91700| Train Loss = 9.901122093200684| Val acc = 0.8503333333333334\n",
            "Steps 91800| Train Loss = 9.275869369506836| Val acc = 0.8493333333333334\n",
            "Steps 91900| Train Loss = 12.934734344482422| Val acc = 0.8516666666666667\n",
            "Steps 92000| Train Loss = 5.584831714630127| Val acc = 0.8483333333333334\n",
            "Steps 92100| Train Loss = 7.413661956787109| Val acc = 0.8503333333333334\n",
            "Steps 92200| Train Loss = 13.043841361999512| Val acc = 0.852\n",
            "Steps 92300| Train Loss = 8.25935173034668| Val acc = 0.8526666666666667\n",
            "Steps 92400| Train Loss = 11.452293395996094| Val acc = 0.8536666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model\n",
        "best_model.load_state_dict(torch.load('best.ckpt'))\n",
        "best_model = best_model.eval()\n",
        "\n",
        "y_test = []\n",
        "for x in test_dataloader:\n",
        "  x = x.to(device)\n",
        "  y = best_model(x)\n",
        "  y_test.append(((y > 0) * 1).item())\n",
        "\n"
      ],
      "metadata": {
        "id": "42J0DE2DQQ8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('predict.csv', 'w', newline='') as csvf:\n",
        "    # 建立 CSV 檔寫入器\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i in range(len(y_test)):\n",
        "      writer.writerow( [i + 1, int(y_test[i])] )"
      ],
      "metadata": {
        "id": "sYJnjxOiQKqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}